{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"DARTS nextgen","text":"<p>Panarctic Database of Active Layer Detatchment Slides and Retrogressive Thaw Slumps from Deep Learning on High Resolution Satellite Imagery. This is te successor of the thaw-slump-segmentation (pipeline), with which the first version of the DARTS dataset was created.</p> Table of Contents<ul> <li>DARTS nextgen<ul> <li>Environment setup<ul> <li>Troubleshoot: Rye can't find the right versions</li> </ul> </li> <li>Contribute</li> </ul> </li> </ul>"},{"location":"#environment-setup","title":"Environment setup","text":"<p>Prereq:</p> <ul> <li>Rye: <code>curl -sSf https://rye.astral.sh/get | bash</code></li> <li>GDAL: <code>sudo apt update &amp;&amp; sudo apt install libpq-dev gdal-bin libgdal-dev</code> or for HPC <code>conda install conda-forge::gdal</code></li> <li>Clang: <code>sudo apt update &amp;&amp; sudo apt install clang</code> or for HPC <code>conda install conda-forge::clang_linux-64</code></li> </ul> <p>If you install GDAL via apt for linux you can view the supported versions here: https://pkgs.org/search/?q=libgdal-dev. For a finer controll over the versions please use conda.</p> <p>Now first check your gdal-version:</p> <pre><code>$ gdal-config --version\n3.9.2\n</code></pre> <p>And your CUDA version (if you want to use CUDA):</p> <pre><code>$ nvidia-smi\n# Now look on the top right of the table\n</code></pre> <p>The GDAL version is relevant, since the version of the python bindings needs to match the installed GDAL version</p> <p>Now, to sync with a specific <code>gdal</code> version, add <code>darts-preprocessing/gdalXX</code> to the <code>--features</code> flag. To sync with a specific <code>cuda</code> version, add <code>darts-ensemble/cuda1X</code> or without cuda <code>darts-ensemble/cpu</code>. E.g.:</p> <pre><code>rye sync -f --features darts-preprocessing/gdal39,darts-ensemble/cuda12 # For CUDA 12 and GDAL 3.9.2\n</code></pre> <p>As of right now, the supported <code>gdal</code> versions are: 3.9.2 (<code>gdal39</code>), 3.8.5 (<code>gdal38</code>), 3.8.4 (<code>gdal384</code>), 3.7.3 (<code>gdal37</code>) and 3.6.4 (<code>gdal36</code>). If your GDAL version is not supported (yet) please sync without GDAL and then install GDAL to an new optional group. For example, if your GDAL version is 3.8.4:</p> <pre><code>rye sync -f\nrye add --optional=gdal384 \"gdal==3.8.4\"\n</code></pre> <p>IMPORTANT! If you installed any of clang or gdal with conda, please ensure that while installing dependencies and working on the project to have the conda environment activated in which you installed clang and or gdal.</p>"},{"location":"#troubleshoot-rye-cant-find-the-right-versions","title":"Troubleshoot: Rye can't find the right versions","text":"<p>Because the <code>pyproject.toml</code> specifies additional sources, e.g. <code>https://download.pytorch.org/whl/cpu</code>, it can happen that the a package with an older version is found in these package-indexes. If such a version is found, <code>uv</code> (the installer behind <code>Rye</code>) currently stops searching other sources for the right version and stops with an <code>Version not found</code> error. This can look something like this:</p> <pre><code>No solution found when resolving dependencies:\n  \u2570\u2500\u25b6 Because only torchmetrics==1.0.3 is available and you require torchmetrics&gt;=1.4.1, we can conclude that your requirements are unsatisfiable.\n</code></pre> <p>To fix this you can set an environment variable to tell <code>uv</code> to search all package-indicies:</p> <pre><code>UV_INDEX_STRATEGY=\"unsafe-best-match\" rye sync ...\n</code></pre> <p>I recommend adding the following to your <code>.zshrc</code> or <code>.bashrc</code>:</p> <pre><code># Change the behaviour of uv package resolution to enable additional sources without breaking existing version-requirements\nexport UV_INDEX_STRATEGY=\"unsafe-best-match\"\n</code></pre> <p>Please see these issues:</p> <ul> <li>Rye: Can't specify per-dependency package index / can't specify uv behavior in config file</li> <li>UV: Add support for pinning a package to a specific index</li> </ul>"},{"location":"#contribute","title":"Contribute","text":"<p>Before contributing please contact one of the authors and make sure to read the Contribution Guidelines.</p>"},{"location":"contribute/","title":"Contribute","text":"<p>This page is also meant for internal documentation.</p>"},{"location":"contribute/#editor-setup","title":"Editor setup","text":"<p>There is only setup files provided for VSCode and no other editor (yet). A list of extensions and some settings can be found in the <code>.vscode</code>. At the first start, VSCode should ask you if you want to install the recommended extension. The settings should be automaticly used by VSCode. Both should provide the developers with a better experience and enforce code-style.</p>"},{"location":"contribute/#architecture-describtion","title":"Architecture describtion","text":"<p>This repository is a workspace repository, managed by Rye. Read more about workspaces at the Rye docs. Each workspace-member starts with <code>darts-*</code> and can be seen as an own package, exexpt the <code>darts-pipeline</code> member. Each package has it's own internal functions and it's public facing API. The public facing API of each package MUST follow the following section API paradigms. The <code>darts-pipeline</code> is a <code>virtual</code> project, hence it can't be installed as a package and has no public facing API.</p> Package Name Type Description (Major) Dependencies - all need Xarray Public Methods* <code>darts-ensemble</code> Ensemble Ensembles the different models and run the multi-stage inference pipeline. PyTorch, <code>darts-superresolution</code>, <code>darts-detection</code>, <code>darts-segmentation</code> <code>Ensemble.infer</code> <code>darts-preprocessing</code> Data Loads data and combines the features to a Xarray Dataset GDAL <code>scene_to_tiles</code>, <code>preprocess</code> <code>darts-acquisition</code> Data Fetches data from the data sources GEE, rasterio, ? <code>fetch_tcvis</code>, <code>fetch_s2</code>, <code>fetch_planet</code> <code>darts-export</code> Data Saves the results from inference and combines the result to the final DARTS dataset GeoPandas, Scipy, Cucim <code>export_tile</code> <code>darts-superresolution</code> Train Trains a supper resolution model to scale Sentinel 2 images from 10m to 3m resolution PyTorch TBD <code>darts-detection</code> Train Trains an object detection model PyTorch TBD <code>darts-segmentation</code> Train Trains an segmentation model PyTorch, segmentation_models_pytorch TBD <code>darts-?</code> Train Trains a ? ? TBD <code>darts-evaluation</code> Test Evaluates the end-to-end process on a test dataset and external dataset GeoPandas <code>test_lewkowicz</code>, <code>test_ensemble</code> <code>darts-utils</code> Data Shared utilities for data processing Scipy, Cucim, GeoPandas TBD <code>darts-train-utils</code> Train Shared utilities for training PyTorch TBD <p>* : These public facing function (-names) are no hard requirements, they should rather help getting an idea of what and where needs to be implemented.</p> <p>The <code>darts-pipeline</code> utilized Ray to automaticly parallize the different computations. However, each package should be designed so that one could build their own pipeline without Ray. Hence, all Ray-related functions / transformations etc. should be defined in the <code>darts-pipeline</code> project.</p> <p>The packages can decide to wrap their public functions into a CLI with typer.</p> <p>The <code>Train</code> packages should also hold the code for training specific data preparation, model training and model evaluation. These packages should get their data from (already processed) data from the <code>darts-preprocessing</code> package. They should expose a statefull Model class with an <code>inference</code> function, which can be used by the <code>darts-ensemble</code> package.</p> <p>TBD: Would it be better if all \"inference\" functions are part of the <code>darts-ensemble</code> package? This would remove the dependency to each of the training repositories and with that potential dependencies to unused training-specific libraries (e.g. pytorch lightning) TBD: Should the <code>darts-ensemble</code> package be split into <code>darts-inference</code> and <code>darts-ensemble</code>? - No TBD: Should the <code>darts-evaluation</code> package be merged into the <code>darts-ensemble</code> package? - No  </p> <p>The packages should follow this architecture: </p>"},{"location":"contribute/#conceptual-migration-from-thaw-slump-segmentation","title":"Conceptual migration from thaw-slump-segmentation","text":"<ul> <li>The <code>darts-ensemble</code> package is the successor of the <code>process-02-inference</code> and <code>process-03-ensemble</code> scripts.</li> <li>The <code>darts-preprocessing</code> and <code>darts-acquisition</code> packages are the successors of the <code>setup-raw-data</code> script and manual work of obtaining data.</li> <li>The <code>darts-export</code> package is splitted from the  <code>inference</code> script, should include the previous manual works of combining everything into the final dataset.</li> <li>The <code>darts-superresolution</code> package is the successor of the <code>superresolution</code> repository.</li> <li>The <code>darts-detection</code> package is a new package.</li> <li>The <code>darts-segmentation</code> package is the successor of the <code>train</code> and <code>prepare_data</code> script.</li> <li>The <code>darts-evaluation</code> package is the successor of the different manual evaluations.</li> </ul>"},{"location":"contribute/#inference-pipeline-steps","title":"Inference pipeline steps","text":"<p>TODO: This is a draft and should be discussed</p>"},{"location":"contribute/#api-paradigms","title":"API paradigms","text":"<p>The packages should pass the data as Xarray Datasets between each other. Datasets can hold coordinate information aswell as other metadata (like CRS) in a single self-describing object. Since different <code>tiles</code> do not share the same coordinates or metadata, each <code>tile</code> should be represented by a single Xarray <code>Dataset</code>.</p> <ul> <li>Each public facing API function which in some way transforms data should accept a Xarray Dataset as input and return an Xarray Dataset.</li> <li>Data can also be accepted as a list of Xarray Dataset as input and returned as a list of Xarray Datasets for batched processing.     In this case, concattenation should happend internally and on <code>numpy</code> or <code>pytorch</code> level, NOT on <code>xarray</code> abstraction level.     The reason behind this it that the tiles don't share their coordinates, resulting in a lot of empty spaces between the tiles and high memory usage.     The name of the function should then be <code>function_batched</code>.</li> <li>Each public facing API function which loads data should return a single Xarray Dataset for each <code>tile</code>.</li> <li>Data should NOT be saved to file internally, with <code>darts-export</code> as the only exception. Instead, data should returned in-memory as a Xarray Dataset, so the user / pipeline can decide what to save and when.</li> <li>Function names should be verbs, e.g. <code>process</code>, <code>ensemble</code>, <code>do_inference</code>.</li> <li>If a function is stateless it should NOT be part of a class or wrapper</li> <li>If a function is stateful it should be part of a class or wrapper, this is important for Ray</li> </ul> <p>Here are some examples, how these API paradigms should look like.</p> <ol> <li> <p>Single transformation</p> <pre><code>import darts-package\nimport xarray as xr\n\n# User loads / creates the dataset (a single tile) by themself\nds = xr.open_dataset(\"...\")\n\n# User calls the function to transform the dataset\nds = darts-package.transform(ds, **kwargs)\n\n# User can decide by themself what to do next, e.g. save\nds.to_netcdf(\"...\")\n</code></pre> </li> <li> <p>Batched transformation</p> <pre><code>import darts_package\nimport xarray as xr\n\n# User loads / creates multiple datasets (hence, multiple tiles) by themself\ndata = [xr.open_dataset(\"...\"), xr.open_dataset(\"...\"), ...]\n\n# User calls the function to transform the dataset\ndata = darts_package.transform_batched(data, **kwargs)\n\n# User can decide by themself what to do next\ndata[0].whatever()\n</code></pre> </li> <li> <p>Load &amp; preprocess some data</p> <pre><code>import darts_package\n\n# User calls the function to transform the dataset\nds = darts_package.load(\"path/to/data\", **kwargs)\n\n# User can decide by themself what to do next\nds.whatever()\n</code></pre> </li> <li> <p>Custom pipeline example</p> <pre><code>from pathlib import Path\nimport darts_preprocess\nimport darts_inference\n\nDATA_DIR = Path(\"./data/\")\nMODEL_DIR = Path(\"./models/\")\nOUT_DIR = Path(\"./out/\")\n\n# Inference is a stateful transformation, because it needs to load the model\n# Hence, the \nensemble = darts_inference.Ensemble.load(MODEL_DIR)\n\n# The data directory contains subfolders which then hold the input data\nfor dir in DATA_DIR:\n    name = dir.name\n\n    # Load the files from the processing directory\n    ds = darts_preprocess.load_and_preprocess(dir)\n\n    # Do the inferencce\n    ds = ensemble.inference(ds)\n\n    # Save the results\n    ds.to_netcdf(OUT_DIR / f\"{name}-result.nc\")\n</code></pre> </li> <li> <p>Pipeline with Ray</p> <pre><code>from dataclasses import dataclass\nfrom pathlib import Path\nimport ray\nimport darts_preprocess\nimport darts_inference\nimport darts_export\n\nDATA_DIR = Path(\"./data/\")\nMODEL_DIR = Path(\"./models/\")\nOUT_DIR = Path(\"./out/\")\n\nray.init()\n\n# We need to wrap the Xarray dataset in a class, so that Ray can serialize it\n@dataclass\nclass Tile:\n    ds: xr.Dataset\n\n# Wrapper for ray\ndef open_dataset_ray(row: dict[str, Any]) -&gt; dict[str, Any]:\n    data = xr.open_dataset(row[\"path\"])\n    tile = Tile(data)\n    return {\n        \"input\": tile,\n    }\n\n# Wrapper for the preprocessing -&gt; Stateless\ndef preprocess_tile_ray(row: dict[str, Tile]) -&gt; dict[str, Tile]:\n    ds = darts_preprocess.preprocess(row[\"input\"].ds)\n    return {\n        \"preprocessed\": Tile(ds),\n        \"input\": row[\"input\"]\n    }\n\n# Wrapper for the inference -&gt; Statefull\nclass EnsembleRay:\n    def __init__(self):\n        self.ensemble = darts_inference.Ensemble.load(MODEL_DIR)\n\n    def __call__(self, row: dict[str, Tile]) -&gt; dict[str, Tile]:\n        ds = self.ensemble.inference(row[\"preprocessed\"].ds)\n        return {\n            \"output\": Tile(ds),\n            \"preprocessed\": row[\"preprocessed\"],\n            \"input\": row[\"input\"],\n        }\n\n# We need to add 'local:///' to tell ray that we want to use the local filesystem\nfiles = data.glob(\"*.nc\")\nfile_list = [f\"local:////{file.resolve().absolute()}\" for file in files]\n\nds = ray.data.read_binary_files(file_list, include_paths=True)\nds = ds.map(open_dataset_ray) # Lazy open\nds = ds.map(preprocess_tile_ray) # Lazy preprocess\nds = ds.map(EnsembleRay) # Lazy inference\n\n# Save the results\nfor row in ds.iter_rows():\n    darts_export.save(row[\"output\"].ds, OUT_DIR / f\"{row['input'].ds.name}-result.nc\")\n</code></pre> </li> </ol>"},{"location":"contribute/#about-the-xarray-overhead-with-ray","title":"About the Xarray overhead with Ray","text":"<p>Ray expects batched data to be in either numpy or pandas format and can't work with Xarray datasets directly. Hence, a wrapper with custom stacking functions is needed. This tradeoff is not small, however, the benefits in terms of maintainability and readability are worth it.</p> <p></p>"},{"location":"contribute/#package-dependencies","title":"Package dependencies","text":"<p>Each package should define it's own dependencies in it's respective <code>pyproject.toml</code> file. Also, the dependencies should be as minimal as possible. Especially with <code>gdal</code> and <code>torch</code>, they should only be required where needed, since their setup is more complicated.</p>"},{"location":"contribute/#new-package","title":"New package","text":"<p>A new package can easily created with:</p> <pre><code>rye init darts-packagename\n</code></pre> <p>Rye creates a minimal project structure for us.</p> <p>The following things needs to be updates:</p> <ol> <li>The <code>pyproject.toml</code> file inside the new package.</li> </ol> <p>Add to the <code>pyproject.toml</code> file inside the new package is the following to enable Ruff:</p> <pre><code>```toml\n[tool.ruff]\n# Extend the `pyproject.toml` file in the parent directory...\nextend = \"../pyproject.toml\"\n```\n\nPlease also provide a description and a list of authors to the file.\n</code></pre> <ol> <li> <p>The <code>.github/workflows/update_version.yml</code> file, to include the package in the workflow.</p> <p>Under <code>package</code> and under step <code>Update version in pyproject.toml</code>.</p> </li> <li> <p>The docs by creating a new directory with a <code>quickstart.md</code> and a <code>ref.md</code> (and optionally more) and add them to the nav inside the <code>mkdocs.yml</code>.</p> <p>To enable code detection, also add the package directory under <code>plugins</code> in the <code>mkdocs.yml</code>. Please also add the refs to the top-level <code>ref.md</code>.</p> </li> <li> <p>The Readme of the package</p> </li> </ol>"},{"location":"contribute/#documentation","title":"Documentation","text":"<p>The documentation is made with Material for Mkdocs. To build and serve locally the docs you need run with rye:</p> <pre><code>rye run mkdocs serve\n</code></pre>"},{"location":"ref/","title":"Combined Reference","text":"<p>All references on one page</p> Table of Contents<ul> <li>Combined Reference<ul> <li>\u00a0darts_acquisition<ul> <li>Functions<ul> <li>\u00a0hello</li> </ul> </li> </ul> </li> <li>\u00a0darts_ensemble<ul> <li>Functions<ul> <li>\u00a0hello</li> </ul> </li> </ul> </li> <li>\u00a0darts_export<ul> <li>Functions<ul> <li>\u00a0hello</li> </ul> </li> </ul> </li> <li>\u00a0darts_preprocessing<ul> <li>Functions<ul> <li>\u00a0hello</li> </ul> </li> </ul> </li> <li>\u00a0darts_segmentation<ul> <li>Functions<ul> <li>\u00a0hello</li> </ul> </li> </ul> </li> <li>\u00a0darts_superresolution<ul> <li>Functions<ul> <li>\u00a0hello</li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"ref/#darts_acquisition","title":"<code>darts_acquisition</code>","text":"<p>Acquisition of data from various sources for the DARTS dataset.</p>"},{"location":"ref/#darts_acquisition-functions","title":"Functions","text":""},{"location":"ref/#darts_acquisition.hello","title":"<code>hello(name)</code>","text":"<p>Say hello to the user.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the user.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Greating message.</p> Source code in <code>darts-acquisition/src/darts_acquisition/__init__.py</code> <pre><code>def hello(name: str) -&gt; str:\n    \"\"\"Say hello to the user.\n\n    Args:\n        name (str): Name of the user.\n\n    Returns:\n        str: Greating message.\n\n    \"\"\"\n    return f\"Hello, {name}, from darts-acquisition!\"\n</code></pre>"},{"location":"ref/#darts_ensemble","title":"<code>darts_ensemble</code>","text":"<p>Inference and model ensembling for the DARTS dataset.</p>"},{"location":"ref/#darts_ensemble-functions","title":"Functions","text":""},{"location":"ref/#darts_ensemble.hello","title":"<code>hello()</code>","text":"<p>Say hello to the user.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Greating message.</p> Source code in <code>darts-ensemble/src/darts_ensemble/__init__.py</code> <pre><code>def hello() -&gt; str:\n    \"\"\"Say hello to the user.\n\n    Returns:\n        str: Greating message.\n\n    \"\"\"\n    return \"Hello from darts-ensemble!\"\n</code></pre>"},{"location":"ref/#darts_export","title":"<code>darts_export</code>","text":"<p>Dataset export for the DARTS dataset.</p>"},{"location":"ref/#darts_export-functions","title":"Functions","text":""},{"location":"ref/#darts_export.hello","title":"<code>hello()</code>","text":"<p>Say hello to the user.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Greating message.</p> Source code in <code>darts-export/src/darts_export/__init__.py</code> <pre><code>def hello() -&gt; str:\n    \"\"\"Say hello to the user.\n\n    Returns:\n        str: Greating message.\n\n    \"\"\"\n    return \"Hello from darts-export!\"\n</code></pre>"},{"location":"ref/#darts_preprocessing","title":"<code>darts_preprocessing</code>","text":"<p>Data preprocessing and feature engineering for the DARTS dataset.</p>"},{"location":"ref/#darts_preprocessing-functions","title":"Functions","text":""},{"location":"ref/#darts_preprocessing.hello","title":"<code>hello()</code>","text":"<p>Say hello to the user.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Greating message.</p> Source code in <code>darts-preprocessing/src/darts_preprocessing/__init__.py</code> <pre><code>def hello() -&gt; str:\n    \"\"\"Say hello to the user.\n\n    Returns:\n        str: Greating message.\n\n    \"\"\"\n    return \"Hello from darts-preprocessing!\"\n</code></pre>"},{"location":"ref/#darts_segmentation","title":"<code>darts_segmentation</code>","text":"<p>Image segmentation of thaw-slumps for the DARTS dataset.</p>"},{"location":"ref/#darts_segmentation-functions","title":"Functions","text":""},{"location":"ref/#darts_segmentation.hello","title":"<code>hello()</code>","text":"<p>Say hello to the user.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Greating message.</p> Source code in <code>darts-segmentation/src/darts_segmentation/__init__.py</code> <pre><code>def hello() -&gt; str:\n    \"\"\"Say hello to the user.\n\n    Returns:\n        str: Greating message.\n\n    \"\"\"\n    return \"Hello from darts-segmentation!\"\n</code></pre>"},{"location":"ref/#darts_superresolution","title":"<code>darts_superresolution</code>","text":"<p>Image superresolution of Sentinel 2 imagery for the DARTS dataset.</p>"},{"location":"ref/#darts_superresolution-functions","title":"Functions","text":""},{"location":"ref/#darts_superresolution.hello","title":"<code>hello()</code>","text":"<p>Say hello to the user.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Greating message.</p> Source code in <code>darts-superresolution/src/darts_superresolution/__init__.py</code> <pre><code>def hello() -&gt; str:\n    \"\"\"Say hello to the user.\n\n    Returns:\n        str: Greating message.\n\n    \"\"\"\n    return \"Hello from darts-superresolution!\"\n</code></pre>"},{"location":"darts-acquisition/quickstart/","title":"DARTS acquisition","text":"<p>Acquisition of data from various sources for the DARTS dataset.</p>"},{"location":"darts-acquisition/quickstart/#installation","title":"Installation","text":"<pre><code>pip install darts-acquisition\n</code></pre>"},{"location":"darts-acquisition/quickstart/#usage","title":"Usage","text":"<pre><code>import darts_acquisition\n</code></pre>"},{"location":"darts-acquisition/ref/","title":"Acquisition Reference","text":""},{"location":"darts-acquisition/ref/#darts_acquisition","title":"<code>darts_acquisition</code>","text":"<p>Acquisition of data from various sources for the DARTS dataset.</p>"},{"location":"darts-acquisition/ref/#darts_acquisition-functions","title":"Functions","text":""},{"location":"darts-acquisition/ref/#darts_acquisition.hello","title":"<code>hello(name)</code>","text":"<p>Say hello to the user.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the user.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Greating message.</p> Source code in <code>darts-acquisition/src/darts_acquisition/__init__.py</code> <pre><code>def hello(name: str) -&gt; str:\n    \"\"\"Say hello to the user.\n\n    Args:\n        name (str): Name of the user.\n\n    Returns:\n        str: Greating message.\n\n    \"\"\"\n    return f\"Hello, {name}, from darts-acquisition!\"\n</code></pre>"},{"location":"darts-ensemble/quickstart/","title":"DARTS ensemble","text":"<p>Inference and model ensembling for the DARTS dataset.</p>"},{"location":"darts-ensemble/quickstart/#installation","title":"Installation","text":"<pre><code>pip install darts-ensemble\n</code></pre>"},{"location":"darts-ensemble/quickstart/#usage","title":"Usage","text":"<pre><code>import darts_ensemble\n</code></pre>"},{"location":"darts-ensemble/ref/","title":"Ensemble Reference","text":""},{"location":"darts-ensemble/ref/#darts_ensemble","title":"<code>darts_ensemble</code>","text":"<p>Inference and model ensembling for the DARTS dataset.</p>"},{"location":"darts-ensemble/ref/#darts_ensemble-functions","title":"Functions","text":""},{"location":"darts-ensemble/ref/#darts_ensemble.hello","title":"<code>hello()</code>","text":"<p>Say hello to the user.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Greating message.</p> Source code in <code>darts-ensemble/src/darts_ensemble/__init__.py</code> <pre><code>def hello() -&gt; str:\n    \"\"\"Say hello to the user.\n\n    Returns:\n        str: Greating message.\n\n    \"\"\"\n    return \"Hello from darts-ensemble!\"\n</code></pre>"},{"location":"darts-export/quickstart/","title":"DARTS export","text":"<p>Dataset export for the DARTS dataset.</p>"},{"location":"darts-export/quickstart/#installation","title":"Installation","text":"<pre><code>pip install darts-export\n</code></pre>"},{"location":"darts-export/quickstart/#usage","title":"Usage","text":"<pre><code>import darts_export\n</code></pre>"},{"location":"darts-export/ref/","title":"Export Reference","text":""},{"location":"darts-export/ref/#darts_export","title":"<code>darts_export</code>","text":"<p>Dataset export for the DARTS dataset.</p>"},{"location":"darts-export/ref/#darts_export-functions","title":"Functions","text":""},{"location":"darts-export/ref/#darts_export.hello","title":"<code>hello()</code>","text":"<p>Say hello to the user.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Greating message.</p> Source code in <code>darts-export/src/darts_export/__init__.py</code> <pre><code>def hello() -&gt; str:\n    \"\"\"Say hello to the user.\n\n    Returns:\n        str: Greating message.\n\n    \"\"\"\n    return \"Hello from darts-export!\"\n</code></pre>"},{"location":"darts-preprocessing/quickstart/","title":"DARTS preprocessing","text":"<p>Data preprocessing and feature engineering for the DARTS dataset.</p>"},{"location":"darts-preprocessing/quickstart/#installation","title":"Installation","text":"<pre><code>pip install darts-preprocessing\n</code></pre>"},{"location":"darts-preprocessing/quickstart/#usage","title":"Usage","text":"<pre><code>import darts_preprocessing\n</code></pre>"},{"location":"darts-preprocessing/ref/","title":"Preprocessing Reference","text":""},{"location":"darts-preprocessing/ref/#darts_preprocessing","title":"<code>darts_preprocessing</code>","text":"<p>Data preprocessing and feature engineering for the DARTS dataset.</p>"},{"location":"darts-preprocessing/ref/#darts_preprocessing-functions","title":"Functions","text":""},{"location":"darts-preprocessing/ref/#darts_preprocessing.hello","title":"<code>hello()</code>","text":"<p>Say hello to the user.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Greating message.</p> Source code in <code>darts-preprocessing/src/darts_preprocessing/__init__.py</code> <pre><code>def hello() -&gt; str:\n    \"\"\"Say hello to the user.\n\n    Returns:\n        str: Greating message.\n\n    \"\"\"\n    return \"Hello from darts-preprocessing!\"\n</code></pre>"},{"location":"darts-segmentation/quickstart/","title":"DARTS segmentation","text":"<p>Image segmentation of thaw-slumps for the DARTS dataset.</p>"},{"location":"darts-segmentation/quickstart/#installation","title":"Installation","text":"<pre><code>pip install darts-segmentation\n</code></pre>"},{"location":"darts-segmentation/quickstart/#usage","title":"Usage","text":"<pre><code>import darts_segmentation\n</code></pre>"},{"location":"darts-segmentation/ref/","title":"Export Reference","text":""},{"location":"darts-segmentation/ref/#darts_export","title":"<code>darts_export</code>","text":"<p>Dataset export for the DARTS dataset.</p>"},{"location":"darts-segmentation/ref/#darts_export-functions","title":"Functions","text":""},{"location":"darts-segmentation/ref/#darts_export.hello","title":"<code>hello()</code>","text":"<p>Say hello to the user.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Greating message.</p> Source code in <code>darts-export/src/darts_export/__init__.py</code> <pre><code>def hello() -&gt; str:\n    \"\"\"Say hello to the user.\n\n    Returns:\n        str: Greating message.\n\n    \"\"\"\n    return \"Hello from darts-export!\"\n</code></pre>"},{"location":"darts-superresolution/quickstart/","title":"DARTS superresolution","text":"<p>Image superresolution of Sentinel 2 imagery for the DARTS dataset.</p>"},{"location":"darts-superresolution/quickstart/#installation","title":"Installation","text":"<pre><code>pip install darts-superresolution\n</code></pre>"},{"location":"darts-superresolution/quickstart/#usage","title":"Usage","text":"<pre><code>import darts_superresolution\n</code></pre>"},{"location":"darts-superresolution/ref/","title":"Superresolution Reference","text":""},{"location":"darts-superresolution/ref/#darts_superresolution","title":"<code>darts_superresolution</code>","text":"<p>Image superresolution of Sentinel 2 imagery for the DARTS dataset.</p>"},{"location":"darts-superresolution/ref/#darts_superresolution-functions","title":"Functions","text":""},{"location":"darts-superresolution/ref/#darts_superresolution.hello","title":"<code>hello()</code>","text":"<p>Say hello to the user.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Greating message.</p> Source code in <code>darts-superresolution/src/darts_superresolution/__init__.py</code> <pre><code>def hello() -&gt; str:\n    \"\"\"Say hello to the user.\n\n    Returns:\n        str: Greating message.\n\n    \"\"\"\n    return \"Hello from darts-superresolution!\"\n</code></pre>"},{"location":"dev/logging/","title":"Logging","text":"<p>We want to use the python logging module as much as possible to traceback errors and document the pipeline processes. Furthermore, we want to configure each logger with the <code>RichHandler</code>, which prettyfies the output with rich.</p>"},{"location":"dev/logging/#usage-guide","title":"Usage Guide","text":"<p>For logging inside a package should be done without any further configuration:</p> <pre><code>import logging\n\nlogger = logging.getLogger(__name__) # don't replace __name__\n</code></pre> <p>Logging at a top-level can and should be further configured:</p> <p>Code is untested!</p> <pre><code>import logging\n\nfrom rich.logging import RichHandler\n\nconsole_handler = RichHandler(rich_tracebacks=True)\nconsole_handler.setLevel(logging.INFO)\nconsole_handler.setFormatter(logging.Formatter(\"%(message)s\", datefmt=\"[%X]\"))\n\nfile_handler = logging.FileHandler(\"app.log\")\nfile_handler.setLevel(logging.DEBUG)\nfile_handler.setFormatter(logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"))\n\nlogging.basicConfig(handlers=[console_handler, file_handler])\n</code></pre>"},{"location":"dev/logging/#supressing-arrays","title":"Supressing Arrays","text":"<p>When printing or logging large numpy arrays a lot of numbers get truncated, however the array still takes a lot of space. Using <code>lovely_numpy</code> and <code>lovely_tensor</code> can help here:</p> <pre><code>import numyp as np\nimport torch\nimport xarray as xr\nfrom lovely_numpy import lo\nfrom lovely_tensors import monkey_patch\n\nmonkey_patch()\nxr.set_options(display_expand_data=False)\n\na = np.zeros((8, 1024, 1024))\nla = lo(a)\nda = xr.DataArray(a)\nt = torch.tensor(a)\n\nlogger.warning(la)\nlogger.warning(da)\nlogger.warning(t)\n</code></pre>"}]}