from typing import Literal

import pytest

from darts_segmentation.training.scoring import check_score_is_unstable, score_from_runs

# Minimized version of a potential run info generated by the cv
run_infos = [
    {"val/JaccardIndex": 0.75, "val/Recall": 0.83, "val/loss": 0.5},
    {"val/JaccardIndex": 0.7, "val/Recall": 0.8, "val/loss": 0.45},
    {"val/JaccardIndex": 0.65, "val/Recall": 0.75, "val/loss": 0.55},
    {"val/JaccardIndex": 0.8, "val/Recall": 0.85, "val/loss": 0.1},
    {"val/JaccardIndex": 0.73, "val/Recall": 0.82, "val/loss": 2.5},
    {"val/JaccardIndex": 0.68, "val/Recall": 0.77, "val/loss": 1.2},
]

unstable_run_infos = [
    {"val/JaccardIndex": 0.75, "val/Recall": float("inf"), "val/loss": 0.5},
    {"val/JaccardIndex": 0, "val/Recall": 0.8, "val/loss": 0.45},
    {"val/JaccardIndex": 0.65, "val/Recall": 0.75, "val/loss": float("-inf")},
    {"val/JaccardIndex": 0.8, "val/Recall": 0.85, "val/loss": 0.1},
    {"val/JaccardIndex": float("nan"), "val/Recall": 0.82, "val/loss": 2.5},
    {"val/JaccardIndex": 0.68, "val/Recall": 0.77, "val/loss": 1.2},
]

unstable_run_info_selective = {
    "valid": 0.75,
    "zero": 0,
    "nan": float("nan"),
    "inf": float("inf"),
    "neginf": float("-inf"),
}


@pytest.mark.parametrize("direction", ["", ":higher", ":lower"])
def test_single_scoring(direction: Literal["", ":higher", ":lower"]):
    score = score_from_runs(run_infos, "val/JaccardIndex" + direction)
    assert round(score, 3) == 0.718

    score = score_from_runs(run_infos, "val/Recall" + direction)
    assert round(score, 3) == 0.803

    score = score_from_runs(run_infos, "val/loss" + direction)
    assert round(score, 3) == 0.883


def test_multiple_scoring_harmonic():
    score = score_from_runs(run_infos, ["val/JaccardIndex", "val/Recall"], "harmonic")
    assert round(score, 3) == 0.758

    score = score_from_runs(run_infos, ["val/JaccardIndex:higher", "val/Recall:higher", "val/loss:lower"], "harmonic")
    assert round(score, 3) == 0.893


def test_multiple_scoring_arithmetic():
    score = score_from_runs(run_infos, ["val/JaccardIndex", "val/Recall"], "arithmetic")
    assert round(score, 3) == 0.761

    score = score_from_runs(run_infos, ["val/JaccardIndex:higher", "val/Recall:higher", "val/loss:lower"], "arithmetic")
    assert round(score, 3) == 1.467


def test_multiple_scoring_geometric():
    score = score_from_runs(run_infos, ["val/JaccardIndex", "val/Recall"], "geometric")
    assert round(score, 3) == 0.760

    score = score_from_runs(run_infos, ["val/JaccardIndex:higher", "val/Recall:higher", "val/loss:lower"], "geometric")
    assert round(score, 3) == 1.064


def test_multiple_scoring_min():
    score = score_from_runs(run_infos, ["val/JaccardIndex", "val/Recall"], "min")
    assert round(score, 3) == 0.718

    score = score_from_runs(run_infos, ["val/JaccardIndex:higher", "val/Recall:higher", "val/loss:lower"], "min")
    assert round(score, 3) == 0.663


def test_single_stable():
    is_unstable = any(check_score_is_unstable(run_info, "val/JaccardIndex") for run_info in run_infos)
    assert not is_unstable


def test_single_unstable():
    is_unstable = any(check_score_is_unstable(run_info, "val/JaccardIndex") for run_info in unstable_run_infos)
    assert is_unstable


def test_single_unstable_selective():
    is_unstable = check_score_is_unstable(unstable_run_info_selective, "valid")
    assert not is_unstable

    is_unstable = check_score_is_unstable(unstable_run_info_selective, "zero")
    assert is_unstable

    is_unstable = check_score_is_unstable(unstable_run_info_selective, "nan")
    assert is_unstable

    is_unstable = check_score_is_unstable(unstable_run_info_selective, "inf")
    assert is_unstable

    is_unstable = check_score_is_unstable(unstable_run_info_selective, "neginf")
    assert is_unstable
